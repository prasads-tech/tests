name: CI Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  generate_manifests:
    runs-on: ubuntu-latest

    env:
      INPUT_PATH: "./Clusters-Dev/AKS/Input/input.json"
      MAPPING_PATH: "./Cluster-artifacts/Templates/FieldMapping.json"
      TEMPLATE_PATH: "./Cluster-artifacts/Templates/AKS-templates01.yaml"
      OUTPUT_DIR: "./Manifests"

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r Cluster-Management-Repo-dev/requirements.txt

      - name: Run main script
        run: |
          python Cluster-Management-Repo-dev/Automation/AKS/Workload-Cluster/main.py \
            --input ${{ env.INPUT_PATH }} \
            --mapping ${{ env.MAPPING_PATH }} \
            --template ${{ env.TEMPLATE_PATH }}

      - name: Upload Manifests
        uses: actions/upload-artifact@v3
        with:
          name: manifests
          path: ${{ env.OUTPUT_DIR }}





import os
import json
import copy
import argparse
import logging
from dotenv import load_dotenv
import yaml

# Load environment variables from .env file
load_dotenv()

# Get paths from environment variables
input_file = os.getenv("INPUT_PATH")
mapping_file = os.getenv("MAPPING_PATH")
template_file = os.getenv("TEMPLATE_PATH")
output_dir = os.getenv("OUTPUT_DIR")  # Base output directory

logging.basicConfig(level=logging.INFO)

# Your other functions (load_json, validate_and_apply_defaults, replace_placeholders, etc.) would go here...

def generate_output(validated_data):
    """Dynamically generate output filename based on input JSON data"""
    cluster_name = validated_data.get("CLUSTER_NAME", "default")
    environment = validated_data.get("ENV_NAME", "default")
    
    # Use the global output_dir for creating the full path
    output_subdir = os.path.join(output_dir, f"{cluster_name}-{environment}")
    
    # Create the sub-directory if it doesn't exist
    os.makedirs(output_subdir, exist_ok=True)
    
    # Construct the output file name
    output_file_name = f"{cluster_name}-{environment}-definition.yaml"
    
    # Return the full path to the output file inside the created directory
    return os.path.join(output_subdir, output_file_name)

# The rest of your script would go here...

def main():
    """Main function to run the program."""
    # Parse command-line arguments
    parser = argparse.ArgumentParser(
        description="Generate Kubernetes cluster definitions from templates."
    )
    parser.add_argument("--input", required=True, help="Path to the input JSON file")
    parser.add_argument("--mapping", required=True, help="Path to the mapping JSON file")
    parser.add_argument("--template", required=True, help="Path to the YAML template file")

    args = parser.parse_args()

    # Load the mapping and input data
    mapping = load_json(args.mapping)
    inputs = load_json(args.input)

    # Validate inputs and apply defaults
    validated_data, manifests_data = validate_and_apply_defaults(mapping, inputs)

    # Load the YAML template
    with open(args.template, "r", encoding="utf-8") as yaml_file:
        yaml_template = yaml_file.read()

    # Update the YAML template with validated values
    updated_yaml = update_yaml_manifest(yaml_template, validated_data, manifests_data)

    # Get the path to the output file
    output_file_path = generate_output(validated_data)

    # Save the updated YAML manifest
    with open(output_file_path, "w", encoding="utf-8") as updated_yaml_file:
        updated_yaml_file.write(updated_yaml)

    logging.info("Cluster definition saved to '%s'.", output_file_path)


if __name__ == "__main__":
    main()
